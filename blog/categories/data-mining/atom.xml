<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Data Mining | Bing's Blog]]></title>
  <link href="http://binglim.github.com/blog/categories/data-mining/atom.xml" rel="self"/>
  <link href="http://binglim.github.com/"/>
  <updated>2013-04-04T16:45:51+08:00</updated>
  <id>http://binglim.github.com/</id>
  <author>
    <name><![CDATA[Bing]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Notes of Web Intelligence and Big Data - 1 Look]]></title>
    <link href="http://binglim.github.com/blog/2013/04/04/notes-of-web-intelligence-and-big-data-1-look/"/>
    <updated>2013-04-04T13:40:00+08:00</updated>
    <id>http://binglim.github.com/blog/2013/04/04/notes-of-web-intelligence-and-big-data-1-look</id>
    <content type="html"><![CDATA[<h2 id="text-indexing-">Text Indexing 基本文本索引</h2>
<p>当你在网络中搜索文档时，会出现最匹配你查询的关键字的结果。实现这个功能的技术叫做text indexing。</p>

<p>如果使用平衡二叉树，查找一个词需要<em>O(log m)</em>（hashing会更高效一点:<em>O(1+m/K)</em>），如果查询q个关键字，则还要耗费时间<em>O(rq)</em>在整合查询各个关键字的结果上，其中，r是所有中间结果。如果r非常大，就会很耗时。
<!--more--></p>

<h3 id="section">如何创建一个文本索引</h3>
<p>遍历各个文档中的单词并在索引中搜索，如果索引中没有这个单词，就添加一个索引并将索引附在后面，如果已经有了，则直接在索引后面附加这个单词。python伪代码如下：</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">class</span> <span class="nc">index</span><span class="p">:</span>
</span><span class='line'>  <span class="k">def</span> <span class="nf">create</span><span class="p">(</span><span class="n">D</span><span class="p">):</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">D</span><span class="p">:</span>
</span><span class='line'>      <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">d</span><span class="p">:</span>
</span><span class='line'>        <span class="n">i</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">lookup</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
</span><span class='line'>        <span class="k">if</span> <span class="n">i</span> <span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span> <span class="mi">0</span><span class="p">:</span>
</span><span class='line'>          <span class="n">j</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
</span><span class='line'>          <span class="n">index</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">j</span><span class="p">,</span><span class="n">d</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
</span><span class='line'>        <span class="k">else</span><span class="p">:</span>
</span><span class='line'>          <span class="n">index</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">d</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<h3 id="section-1">创建索引的复杂度</h3>
<p>n个文档，m个单词，每个文档w个单词。每个单词都要被读取，时间复杂度至少是<em>O(nw)</em>。此外，我们需要在排序结构中查找m个单词（如果它之前已经被添加在索引中），则时间话费是<em>O(log m)</em>或<em>O(1)</em>（如果使用一个好的哈希表）。我们还必须为每个单词插入包含该单词文档的url，假设每个插入操作耗费的时间都是常数。因此这个过程的复杂性<em>O(nw log m)</em>(使用平衡二叉树来存储单词)或<em>O(nw)</em>（使用哈希表来存储单词）。</p>

<h2 id="page-rank">Page Rank</h2>
<p>一个随机的上网冲浪者访问一个特定页面的概率就是page rank。Page rank是一个全局属性，通过迭代、连续、并行的计算得到。它与相邻矩阵（adjacency matrix）的最大特征向量相关。</p>

<h3 id="section-2">搜索与记忆</h3>
<p>人类记忆与Google的海量索引不同，人们不擅长记忆一些事实，如拿破仑什么时候战败滑铁卢；经常需要环境来增强回忆，如在商场可能就认不出同事；记忆是通过时间链接的；记忆是“模糊”的。</p>

<h3 id="google-and-the-mind">Google and the mind</h3>
<p>我们依赖page-rank越多，page-rank就会变得越糟糕。Page-rank依赖于链接，包含链接是为了更方便地使用google。新的页面只有很少的链接，因此不利于其page-rank的计算。我们很难记住一些事情，所以我们更多地使用Google。Google用得越多，我们记住的越少。然而，我们搜索并获取结果，点击进入网页，这种相关的反馈能够改进搜索（增强page-rank）。</p>

<h3 id="section-3">”私人“搜索</h3>
<p>desktops，email等私人搜索的索引工作遇到的问题：
- 没有链接，不能直接使用page-rank
- 需要使用其它关联性，如命名实体（人，地点）和相关反馈（通过跟踪用户行为）
- 重复检测和处理（如相同的文档拥有多个版本和格式）</p>

<p>除了搜索，还有一些挑战：
- 包括多个角色的语言分析
- 分类
- 安全性-基于角色的访问控制
- 结构化数据</p>

<h3 id="section-4">搜索结构化数据</h3>
<p>在一个错综复杂的关系型数据库中搜索一些特定的内容可能需要查询大量的表，执行大量的SQL语句。要是有许多格式不同的数据库就更糟糕了，最糟糕的是，一些数据在文档中，一些在数据库里。因此，这仍然是一个研究问题。</p>

<h2 id="locality-sensitive-hashinglsd">Locality Sensitive Hashing(LSD)</h2>

<p>反向索引并不是搜索对象最好的方法，另一个强大的方法叫做Locality Sensitive Hashing，它可以比较n对对象在<em>O(n)</em>时间内。</p>

<h3 id="section-5">基本思路</h3>
<p>h(x)是x的哈希函数，如果x等于或接近y，h(x)=h(y)就有很大可能，反之亦然；如果x不等于y或与y差距很大，则h(x)很可以不等于h(y)。</p>

<h3 id="lsh">LSH用于指纹匹配</h3>
<p>如果指纹细节特征点(minutae)匹配，则指纹匹配。Minutae是指指纹中一些特殊情况发生的位置，如两个纹路交汇或者碰到纹路断电的情况。如果用网格来覆盖指纹，那么指纹可以表示成包含有细节特征点的网格块集合。</p>

<p>用f(x)=1表示指纹x在某个特定的k网格位置有细节特征点，用p来表示指纹在一个特定位置有细节特征点的概率，则 $p[f(x)=1]=p^k$。</p>

<p>现在假设有同一个人的另一指纹y，用q来表示y和x有一样的细节特征点的概率，则 $P[f(x)=f(y)=1]=(pq)^k$。 如果我们使用b哥这样的函数f，则至少一个这样的f匹配的概率为 $1-(1-(pq)^k)^b$。但是，如果x不等于y，那么他们至少有一个匹配的概率则为 $1-(1-p^2k)^b$。</p>

<h3 id="lsh-1">一些LSH的大数据应用</h3>
<ul>
  <li>不比较所有的组合对来聚集类似的tweets</li>
  <li>近似文档的检测</li>
  <li>在时间序列中寻找模式（如传感器数据）</li>
  <li>通过多个输入来识别用户</li>
  <li>等等</li>
</ul>

<h3 id="lsh-2">LSH与降维</h3>
<p>LSH能进行高维对象的降维，随机哈希函数是局部敏感的，相似的对象会映射到相似的哈希值。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Notes of Web Intelligence and Big Data - 0 Introduction]]></title>
    <link href="http://binglim.github.com/blog/2013/04/04/notes-of-web-intelligence-and-big-data/"/>
    <updated>2013-04-04T12:10:00+08:00</updated>
    <id>http://binglim.github.com/blog/2013/04/04/notes-of-web-intelligence-and-big-data</id>
    <content type="html"><![CDATA[<h2 id="web-intelligence-and-big-data-on-coursera">Web Intelligence and Big Data on Coursera</h2>
<p>Coursera上的 <em>Web Intelligence and Big Data</em> 开始了，据传说这是一个广度胜于深度的课程，覆盖到了许多话题，对于并非专攻这个领域的人来说，应该是一个很好的知识普及材料。课程是来自印度理工学院（IIT）的，老师也是明显的印度腔，但还不至于听不懂。说话的速度很慢，1.5倍速比较合适。这门课应该起不到练听力的效果了T_T。</p>

<p>这门课程的推荐教材有：</p>

<p><em>Mining Massive Datasets</em> by J.D. Ullman and A. Rajaraman (Cambridge University Press, UK 2012)</p>

<p><em>Introduction to Information Retrieval</em> by Christopher Manning, Prabhakar Raghavan and Hinrich Schutze (Cambridge University Press, UK 2008)</p>

<p><em>Enterprise Cloud Computing</em> by Gautam Shroff (Cambridge University Press, UK 2010)
<!--more-->
前两本书都可以在斯坦福的网站上下到，第三个是教授本人的作品。第一本书比较新，前段时间在各大购书网站上还是很火的，某人那里还有一本，顺手拿来看看。书的封面我很喜欢，纸张质量也很不错，让人很有看的欲望。前两本书都有人翻译过，而且是同一个人翻译的！</p>

<p>更多的，只能等到学习后再说了……</p>

<h2 id="introduction">Introduction</h2>

<h3 id="turing-test">图灵测试（Turing Test）</h3>
<p>图灵测试：一个人通过问两个对象（人和机器）问题来判断哪个是人，哪个是机器，若问了若干问题后仍无法判断，则机器通过图灵测试。</p>

<p>反向图灵测试（Reverse Turing Test）则是由机器提问来判断人和机器，如验证码（CAPTCHA）。</p>

<h3 id="section">大数据技术</h3>
<p>Google, Facebook等并不适用传统的数据库来处理大数据，而事使用大规模并行计算和Map-Reduce范式。</p>

<p>数据的智能：反应智能（Reactive Intelligence）和预测智能（Predictive Intelligence）。</p>

<p>使用人工智能和大数据来预测未来：
Search(Look) -&gt; Machine Learning(Listen) -&gt; Information Extraction(Learn) -&gt; Reasoning(Connect) -&gt; Data Mining(Predict) -&gt; Optimization(Correct).</p>
]]></content>
  </entry>
  
</feed>
